import gradio as gr
import requests
import time
import os
import tempfile
import shutil
import zipfile
from constant import API_URL, CUSTOM_CSS, DEFAULT_AI_MODEL, DEFAULT_MAX_CHUNK_SIZE, DEFAULT_KB_ID
from utils.Logger import logger
from utils.public import process_all_markdown_files, extract_and_find_markdown_files, upload_to_knowledge_base, \
    create_new_zip_with_processed_files, process_all_markdown_files_with_ai


def process_html_file(html_file, upload_to_kb_flag, kb_id, use_ai_flag=True, ai_model=DEFAULT_AI_MODEL,
                       max_chunk_size=DEFAULT_MAX_CHUNK_SIZE, progress=gr.Progress()):
    """å¤„ç†HTMLæ–‡ä»¶ï¼Œç›´æ¥è½¬æ¢ä¸ºMarkdownå¹¶å¤„ç†"""
    if not html_file:
        return {"error": "âŒ è¯·é€‰æ‹©HTMLæ–‡ä»¶"}, None

    try:
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        progress(0.1, desc="ğŸ“‹ å‡†å¤‡å¤„ç†HTMLæ–‡ä»¶...")
        logger.info(f"å‡†å¤‡å¤„ç†HTMLæ–‡ä»¶: {html_file.name}")
        temp_dir = tempfile.mkdtemp()
        
        # åˆ›å»ºä¿å­˜HTMLçš„ä¸´æ—¶è·¯å¾„
        html_temp_path = os.path.join(temp_dir, os.path.basename(html_file.name))
        
        # å¤åˆ¶HTMLæ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        shutil.copyfile(html_file.name, html_temp_path)
        
        # åˆ›å»ºMarkdownè½¬æ¢ç›®å½•
        markdown_dir = os.path.join(temp_dir, "markdown")
        os.makedirs(markdown_dir, exist_ok=True)
        
        # åˆ›å»ºimagesç›®å½•
        images_dir = os.path.join(markdown_dir, "images")
        os.makedirs(images_dir, exist_ok=True)
        
        # ä½¿ç”¨html2textè½¬æ¢HTMLåˆ°Markdown
        progress(0.3, desc="ğŸ”„ æ­£åœ¨è½¬æ¢HTMLåˆ°Markdown...")
        try:
            import html2text
            h = html2text.HTML2Text()
            h.ignore_links = False
            h.ignore_images = False
            h.escape_snob = True
            h.unicode_snob = True
            
            with open(html_temp_path, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            markdown_content = h.handle(html_content)
            
            # ä¿å­˜Markdownæ–‡ä»¶
            markdown_file_path = os.path.join(markdown_dir, f"{os.path.splitext(os.path.basename(html_file.name))[0]}.md")
            with open(markdown_file_path, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
                
            logger.info(f"HTMLå·²è½¬æ¢ä¸ºMarkdown: {markdown_file_path}")
            
            # åˆ›å»ºMarkdownæ–‡ä»¶åˆ—è¡¨
            markdown_files = [markdown_file_path]
            
        except ImportError:
            logger.error("æœªå®‰è£…html2textæ¨¡å—ï¼Œæ— æ³•è½¬æ¢HTML")
            return {"error": "âŒ å¤„ç†å¤±è´¥: æœªå®‰è£…html2textæ¨¡å—"}, None
        except Exception as e:
            logger.error(f"è½¬æ¢HTMLåˆ°Markdownå¤±è´¥: {str(e)}")
            return {"error": f"âŒ è½¬æ¢å¤±è´¥: {str(e)}"}, None
        
        # å¤„ç†é¢å¤–çš„ä¸Šä¼ é€‰é¡¹å’Œå›¾ç‰‡å¤„ç†
        extra_info = {}
        extra_info["æ‰¾åˆ°çš„Markdownæ–‡ä»¶"] = len(markdown_files)
        extra_info["æ‰¾åˆ°çš„imagesç›®å½•"] = 1  # æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªimagesç›®å½•
        
        # æœ€ç»ˆè¾“å‡ºè·¯å¾„ï¼ˆé»˜è®¤ä¸ºZIPæ–‡ä»¶ï¼‰
        output_path = os.path.join(temp_dir, f"{os.path.splitext(os.path.basename(html_file.name))[0]}_results.zip")
        
        # AI å¤§æ¨¡å‹æ¸…æ´—
        ai_success_count = 0
        ai_fail_count = 0
        if use_ai_flag:
            progress(0.6, desc="ğŸ§  æ­£åœ¨ä½¿ç”¨AIä¼˜åŒ–æ–‡æ¡£...")
            logger.info(f"å¼€å§‹ä½¿ç”¨AIå¤§æ¨¡å‹æ¸…æ´—æ–‡æ¡£ï¼Œæ¨¡å‹: {ai_model}ï¼Œæœ€å¤§å—å¤§å°: {max_chunk_size}")
            ai_success_count, ai_fail_count = process_all_markdown_files_with_ai(markdown_files,
                                                                                 ai_model=ai_model,
                                                                                 max_chunk_size=max_chunk_size)
            extra_info[
                "AIä¼˜åŒ–"] = f"âœ… æˆåŠŸ: {ai_success_count} ä¸ªæ–‡ä»¶" if ai_fail_count == 0 else f"âš ï¸ éƒ¨åˆ†æˆåŠŸ: {ai_success_count} æˆåŠŸ, {ai_fail_count} å¤±è´¥"
        else:
            logger.info("è·³è¿‡AIä¼˜åŒ–æ–‡æ¡£")
            extra_info["AIä¼˜åŒ–"] = "â­ï¸ å·²è·³è¿‡"
        
        # åˆ›å»ºåŒ…å«æ‰€æœ‰æ–‡ä»¶çš„ZIP
        progress(0.8, desc="ğŸ“¦ æ­£åœ¨åˆ›å»ºZIPæ–‡ä»¶...")
        with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            # æ·»åŠ æ‰€æœ‰æ–‡ä»¶
            for root, _, files in os.walk(markdown_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œä¿æŒç›®å½•ç»“æ„
                    rel_path = os.path.relpath(file_path, markdown_dir)
                    logger.info(f"æ·»åŠ æ–‡ä»¶åˆ°ZIP: {rel_path}")
                    zipf.write(file_path, rel_path)
        
        final_output_path = output_path
            
        # å¦‚æœé€‰æ‹©äº†ä¸Šä¼ çŸ¥è¯†åº“
        if upload_to_kb_flag:
            if not kb_id:
                logger.warning("æœªæä¾›çŸ¥è¯†åº“IDï¼Œæ— æ³•ä¸Šä¼ ")
                extra_info["çŸ¥è¯†åº“ä¸Šä¼ "] = "âŒ å¤±è´¥: æœªæä¾›çŸ¥è¯†åº“ID"
            else:
                progress(0.9, desc="ğŸ“š æ­£åœ¨ä¸Šä¼ åˆ°çŸ¥è¯†åº“...")
                logger.info(f"å¼€å§‹ä¸Šä¼ åˆ°çŸ¥è¯†åº“ {kb_id}")

                try:
                    # ä¸Šä¼ Markdownæ–‡ä»¶åˆ°çŸ¥è¯†åº“
                    upload_success, upload_result = upload_to_knowledge_base(markdown_dir, kb_id)
                    if upload_success:
                        extra_info["çŸ¥è¯†åº“ä¸Šä¼ "] = f"âœ… æˆåŠŸ (çŸ¥è¯†åº“ID: {kb_id})"
                        extra_info["çŸ¥è¯†åº“ä¸Šä¼ ç»“æœ"] = upload_result
                        logger.info(f"ä¸Šä¼ åˆ°çŸ¥è¯†åº“æˆåŠŸ: {kb_id}")
                    else:
                        extra_info["çŸ¥è¯†åº“ä¸Šä¼ "] = f"âŒ å¤±è´¥: {upload_result.get('é”™è¯¯', 'æœªçŸ¥é”™è¯¯')}"
                        extra_info["çŸ¥è¯†åº“ä¸Šä¼ ç»“æœ"] = upload_result
                        logger.warning(f"ä¸Šä¼ åˆ°çŸ¥è¯†åº“å¤±è´¥: {upload_result}")
                except Exception as e:
                    logger.error(f"ä¸Šä¼ åˆ°çŸ¥è¯†åº“å¤±è´¥: {str(e)}")
                    extra_info["çŸ¥è¯†åº“ä¸Šä¼ "] = f"âŒ å¤±è´¥: {str(e)}"
        
        progress(1.0, desc="ğŸ‰ å¤„ç†å®Œæˆï¼")
        result_info = {
            "status": "âœ… æˆåŠŸ",
            "message": "ğŸ‰ HTMLå¤„ç†æˆåŠŸï¼",
            "æ–‡ä»¶æ•°é‡": len(markdown_files),
            **extra_info
        }
        logger.info(f"å¤„ç†å®Œæˆ: {result_info}")
        return result_info, final_output_path
        
    except Exception as e:
        logger.exception(f"å¤„ç†å‡ºé”™: {str(e)}")
        return {"error": f"âŒ å¤„ç†å¤±è´¥: {str(e)}"}, None


def upload_and_convert_pdf(pdf_file, upload_to_kb_flag, kb_id, use_ai_flag=True, ai_model=DEFAULT_AI_MODEL,
                           max_chunk_size=DEFAULT_MAX_CHUNK_SIZE, progress=gr.Progress()):
    """ä¸Šä¼ PDF/HTMLæ–‡ä»¶å¹¶å¤„ç†"""
    if not pdf_file:
        return {"error": "âŒ è¯·é€‰æ‹©æ–‡ä»¶"}, None
    
    # æ£€æŸ¥æ–‡ä»¶ç±»å‹
    file_extension = os.path.splitext(pdf_file.name)[1].lower()
    
    # å¦‚æœæ˜¯HTMLæ–‡ä»¶ï¼Œä½¿ç”¨HTMLå¤„ç†æµç¨‹
    if file_extension == '.html':
        logger.info(f"æ£€æµ‹åˆ°HTMLæ–‡ä»¶: {pdf_file.name}ï¼Œä½¿ç”¨HTMLå¤„ç†æµç¨‹")
        return process_html_file(pdf_file, upload_to_kb_flag, kb_id, use_ai_flag, ai_model, max_chunk_size, progress)
    
    # å¦åˆ™æŒ‰ç…§åŸPDFå¤„ç†æµç¨‹å¤„ç†
    try:
        # å‡†å¤‡ä¸Šä¼ æ–‡ä»¶
        progress(0.1, desc="ğŸ“‹ å‡†å¤‡ä¸Šä¼ æ–‡ä»¶...")
        logger.info(f"å‡†å¤‡ä¸Šä¼ æ–‡ä»¶: {pdf_file.name}")
        files = {"file": (os.path.basename(pdf_file.name), open(pdf_file.name, "rb"), "application/pdf")}

        # å‘é€è¯·æ±‚
        progress(0.2, desc="ğŸ“¤ æ­£åœ¨ä¸Šä¼ æ–‡ä»¶...")
        response = requests.post(f"{API_URL}/convert/", files=files)
        response.raise_for_status()

        # è§£æå“åº”
        result = response.json()
        task_id = result["task_id"]

        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        progress(0.3, desc="ğŸ”„ æ–‡ä»¶å·²ä¸Šä¼ ï¼Œæ­£åœ¨è½¬æ¢ä¸­...")
        status = "pending"
        start_time = time.time()
        timeout = 600  # 10åˆ†é’Ÿè¶…æ—¶

        while status in ["pending", "processing"]:
            # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
            response = requests.get(f"{API_URL}/status/{task_id}")
            response.raise_for_status()
            result = response.json()
            status = result["status"]

            # å¦‚æœä»»åŠ¡å®Œæˆæˆ–å¤±è´¥ï¼Œé€€å‡ºå¾ªç¯
            if status not in ["pending", "processing"]:
                break

            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if time.time() - start_time > timeout:
                return {"error": "â±ï¸ è½¬æ¢è¶…æ—¶ï¼Œè¯·ç¨åæ£€æŸ¥ç»“æœæˆ–å°è¯•é‡æ–°ä¸Šä¼ "}, None

            # æ›´æ–°è¿›åº¦
            elapsed = time.time() - start_time
            progress_value = min(0.3 + (elapsed / timeout) * 0.6, 0.9)
            progress(progress_value, desc=f"ğŸ”„ æ­£åœ¨è½¬æ¢ä¸­ï¼Œå·²ç”¨æ—¶ {int(elapsed)}ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…...")

            # ç­‰å¾…ä¸€æ®µæ—¶é—´å†æ¬¡æ£€æŸ¥
            time.sleep(3)

        # å¤„ç†ä»»åŠ¡ç»“æœ
        if status == "completed":
            progress(0.95, desc="âœ… è½¬æ¢å®Œæˆï¼Œå‡†å¤‡ä¸‹è½½ç»“æœ...")
            logger.info(f"è½¬æ¢å®Œæˆï¼Œä»»åŠ¡ID: {task_id}")

            # åˆ›å»ºä¸´æ—¶ç›®å½•å­˜å‚¨ä¸‹è½½çš„æ–‡ä»¶
            temp_dir = tempfile.mkdtemp()
            output_path = os.path.join(temp_dir, f"{os.path.basename(pdf_file.name).split('.')[0]}_results.zip")

            # ä¸‹è½½ZIPæ–‡ä»¶
            logger.info(f"ä¸‹è½½ç»“æœæ–‡ä»¶åˆ°: {output_path}")
            response = requests.get(f"{API_URL}/download-zip/{task_id}", stream=True)
            response.raise_for_status()

            with open(output_path, "wb") as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)

            # å¤„ç†é¢å¤–çš„ä¸Šä¼ é€‰é¡¹å’Œå›¾ç‰‡å¤„ç†
            extra_info = {}
            final_output_path = output_path  # é»˜è®¤ä½¿ç”¨åŸå§‹è¾“å‡ºè·¯å¾„

            # è§£å‹å¹¶æŸ¥æ‰¾Markdownæ–‡ä»¶å’Œimagesç›®å½•
            progress(0.96, desc="ğŸ“„ æ­£åœ¨è§£æè½¬æ¢ç»“æœ...")
            extract_dir, markdown_files, images_dirs = extract_and_find_markdown_files(output_path)

            # æ·»åŠ æ‰¾åˆ°çš„æ–‡ä»¶ä¿¡æ¯åˆ°ç»“æœä¸­
            extra_info["æ‰¾åˆ°çš„Markdownæ–‡ä»¶"] = len(markdown_files)
            extra_info["æ‰¾åˆ°çš„imagesç›®å½•"] = len(images_dirs)

            # å¤„ç†æ‰€æœ‰Markdownæ–‡ä»¶ä¸­çš„å›¾ç‰‡é“¾æ¥
            if markdown_files:
                progress(0.97, desc="ğŸ–¼ï¸ æ­£åœ¨å¤„ç†å›¾ç‰‡é“¾æ¥...")
                logger.info("å¼€å§‹å¤„ç†æ‰€æœ‰Markdownæ–‡ä»¶ä¸­çš„å›¾ç‰‡é“¾æ¥")
                success, stats = process_all_markdown_files(extract_dir, markdown_files)

                # AI å¤§æ¨¡å‹æ¸…æ´—
                ai_success_count = 0
                ai_fail_count = 0
                if use_ai_flag:
                    progress(0.98, desc="ğŸ§  æ­£åœ¨ä½¿ç”¨AIä¼˜åŒ–æ–‡æ¡£...")
                    logger.info(f"å¼€å§‹ä½¿ç”¨AIå¤§æ¨¡å‹æ¸…æ´—æ–‡æ¡£ï¼Œæ¨¡å‹: {ai_model}ï¼Œæœ€å¤§å—å¤§å°: {max_chunk_size}")
                    ai_success_count, ai_fail_count = process_all_markdown_files_with_ai(markdown_files,
                                                                                         ai_model=ai_model,
                                                                                         max_chunk_size=max_chunk_size)
                    extra_info[
                        "AIä¼˜åŒ–"] = f"âœ… æˆåŠŸ: {ai_success_count} ä¸ªæ–‡ä»¶" if ai_fail_count == 0 else f"âš ï¸ éƒ¨åˆ†æˆåŠŸ: {ai_success_count} æˆåŠŸ, {ai_fail_count} å¤±è´¥"
                else:
                    logger.info("è·³è¿‡AIä¼˜åŒ–æ–‡æ¡£")
                    extra_info["AIä¼˜åŒ–"] = "â­ï¸ å·²è·³è¿‡"

                # åˆ›å»ºåŒ…å«å¤„ç†åæ–‡ä»¶çš„æ–°ZIP
                progress(0.99, desc="ğŸ“¦ æ­£åœ¨åˆ›å»ºæ–°çš„ZIPæ–‡ä»¶...")
                final_output_path = create_new_zip_with_processed_files(output_path, extract_dir)

                # æ·»åŠ å¤„ç†ç»Ÿè®¡ä¿¡æ¯
                extra_info["å›¾ç‰‡å¤„ç†"] = "âœ… æˆåŠŸ" if success else "âš ï¸ éƒ¨åˆ†æˆåŠŸ"
                extra_info["å¤„ç†ç»Ÿè®¡"] = stats

            # å¦‚æœé€‰æ‹©äº†ä¸Šä¼ çŸ¥è¯†åº“
            if upload_to_kb_flag:
                if not kb_id:
                    logger.warning("æœªæä¾›çŸ¥è¯†åº“IDï¼Œæ— æ³•ä¸Šä¼ ")
                    extra_info["çŸ¥è¯†åº“ä¸Šä¼ "] = "âŒ å¤±è´¥: æœªæä¾›çŸ¥è¯†åº“ID"
                else:
                    progress(0.99, desc="ğŸ“š æ­£åœ¨ä¸Šä¼ åˆ°çŸ¥è¯†åº“...")
                    logger.info(f"å¼€å§‹ä¸Šä¼ åˆ°çŸ¥è¯†åº“ {kb_id}")

                    try:
                        # ä½¿ç”¨å·²ç»å¤„ç†è¿‡å›¾ç‰‡çš„æ–‡ä»¶è¿›è¡Œä¸Šä¼ 
                        upload_success, upload_result = upload_to_knowledge_base(extract_dir, kb_id)
                        if upload_success:
                            extra_info["çŸ¥è¯†åº“ä¸Šä¼ "] = f"âœ… æˆåŠŸ (çŸ¥è¯†åº“ID: {kb_id})"
                            extra_info["çŸ¥è¯†åº“ä¸Šä¼ ç»“æœ"] = upload_result
                            logger.info(f"ä¸Šä¼ åˆ°çŸ¥è¯†åº“æˆåŠŸ: {kb_id}")
                        else:
                            extra_info["çŸ¥è¯†åº“ä¸Šä¼ "] = f"âŒ å¤±è´¥: {upload_result.get('é”™è¯¯', 'æœªçŸ¥é”™è¯¯')}"
                            extra_info["çŸ¥è¯†åº“ä¸Šä¼ ç»“æœ"] = upload_result
                            logger.warning(f"ä¸Šä¼ åˆ°çŸ¥è¯†åº“å¤±è´¥: {upload_result}")
                    except Exception as e:
                        logger.error(f"ä¸Šä¼ åˆ°çŸ¥è¯†åº“å¤±è´¥: {str(e)}")
                        extra_info["çŸ¥è¯†åº“ä¸Šä¼ "] = f"âŒ å¤±è´¥: {str(e)}"

            progress(1.0, desc="ğŸ‰ è½¬æ¢å®Œæˆï¼")
            result_info = {
                "status": "âœ… æˆåŠŸ",
                "message": "ğŸ‰ PDFè½¬æ¢æˆåŠŸï¼",
                "task_id": task_id,
                "æ–‡ä»¶æ•°é‡": len(result.get("files", [])) if result.get("files") else 0,
                **extra_info
            }
            logger.info(f"å¤„ç†å®Œæˆ: {result_info}")
            return result_info, final_output_path
        else:
            error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
            logger.error(f"è½¬æ¢å¤±è´¥: {error_msg}")
            return {"error": f"âŒ è½¬æ¢å¤±è´¥: {error_msg}"}, None

    except Exception as e:
        logger.exception(f"å¤„ç†å‡ºé”™: {str(e)}")
        return {"error": f"âŒ å¤„ç†å¤±è´¥: {str(e)}"}, None


def show_kb_id_input(upload_to_kb):
    """æ ¹æ®æ˜¯å¦é€‰æ‹©ä¸Šä¼ çŸ¥è¯†åº“æ¥æ˜¾ç¤ºæˆ–éšè—çŸ¥è¯†åº“IDè¾“å…¥æ¡†"""
    return gr.update(visible=upload_to_kb)


def process_multiple_files(pdf_files, upload_to_kb_flag, kb_id, use_ai_flag=True, ai_model=DEFAULT_AI_MODEL,
                           max_chunk_size=DEFAULT_MAX_CHUNK_SIZE, progress=gr.Progress()):
    """å¤„ç†å¤šä¸ªPDF/HTMLæ–‡ä»¶"""
    if not pdf_files:
        return {"error": "âŒ è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ–‡ä»¶"}, None
    
    # å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œç›´æ¥è°ƒç”¨å•æ–‡ä»¶å¤„ç†å‡½æ•°
    if len(pdf_files) == 1:
        pdf_file = pdf_files[0]
        file_extension = os.path.splitext(pdf_file.name)[1].lower()
        
        if file_extension == '.html':
            return process_html_file(pdf_file, upload_to_kb_flag, kb_id, use_ai_flag, ai_model, max_chunk_size, progress)
        else:
            return upload_and_convert_pdf(pdf_file, upload_to_kb_flag, kb_id, use_ai_flag, ai_model, max_chunk_size, progress)
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•æ¥å­˜å‚¨æ‰€æœ‰å¤„ç†ç»“æœ
    main_temp_dir = tempfile.mkdtemp()
    main_output_path = os.path.join(main_temp_dir, "combined_results.zip")
    
    # ç”¨äºå­˜å‚¨æ‰€æœ‰å¤„ç†ç»“æœ
    all_results = {}
    all_extract_dirs = []
    success_count = 0
    fail_count = 0
    
    # æ€»æ­¥éª¤æ•° = æ–‡ä»¶æ•°
    total_files = len(pdf_files)
    
    try:
        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        for i, pdf_file in enumerate(pdf_files):
            file_name = os.path.basename(pdf_file.name)
            file_progress_base = i / total_files
            file_progress_step = 1 / total_files
            
            # æ›´æ–°è¿›åº¦æ¡
            progress(file_progress_base, desc=f"ğŸ“„ å¤„ç†æ–‡ä»¶ {i+1}/{total_files}: {file_name}")
            logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶ {i+1}/{total_files}: {file_name}")
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹è°ƒç”¨ç›¸åº”çš„å¤„ç†å‡½æ•°
            file_extension = os.path.splitext(file_name)[1].lower()
            
            # åˆ›å»ºä¸€ä¸ªå­è¿›åº¦æ¡å‡½æ•°
            def sub_progress(value, desc=""):
                # å°†å­è¿›åº¦æ˜ å°„åˆ°æ€»è¿›åº¦çš„å¯¹åº”éƒ¨åˆ†
                overall_value = file_progress_base + (value * file_progress_step)
                progress(min(overall_value, 0.99), desc=f"ğŸ“„ {file_name}: {desc}")
            
            try:
                if file_extension == '.html':
                    # å¤„ç†HTMLæ–‡ä»¶
                    result, output_path = process_html_file(
                        pdf_file, upload_to_kb_flag, kb_id, use_ai_flag, ai_model, max_chunk_size, 
                        gr.Progress(lambda v, d: sub_progress(v, d))
                    )
                else:
                    # å¤„ç†PDFæ–‡ä»¶
                    result, output_path = upload_and_convert_pdf(
                        pdf_file, upload_to_kb_flag, kb_id, use_ai_flag, ai_model, max_chunk_size, 
                        gr.Progress(lambda v, d: sub_progress(v, d))
                    )
                
                if "error" not in result:
                    success_count += 1
                    all_results[file_name] = result
                    
                    # å¦‚æœæœ‰è¾“å‡ºè·¯å¾„ï¼Œè§£å‹å®ƒä»¥ä¾¿åˆå¹¶
                    if output_path and os.path.exists(output_path):
                        extract_dir, _, _ = extract_and_find_markdown_files(output_path)
                        all_extract_dirs.append((file_name, extract_dir))
                else:
                    fail_count += 1
                    all_results[file_name] = result
            except Exception as e:
                logger.exception(f"å¤„ç†æ–‡ä»¶ {file_name} æ—¶å‡ºé”™: {e}")
                fail_count += 1
                all_results[file_name] = {"error": f"âŒ å¤„ç†å¤±è´¥: {str(e)}"}
        
        # åˆ›å»ºåˆå¹¶çš„ZIPæ–‡ä»¶
        progress(0.95, desc="ğŸ“¦ æ­£åœ¨åˆ›å»ºåˆå¹¶çš„ZIPæ–‡ä»¶...")
        with zipfile.ZipFile(main_output_path, 'w', zipfile.ZIP_DEFLATED) as main_zip:
            # æ·»åŠ æ¯ä¸ªå¤„ç†å¥½çš„ç›®å½•åˆ°ZIPä¸­
            for file_name, extract_dir in all_extract_dirs:
                base_name = os.path.splitext(file_name)[0]
                for root, _, files in os.walk(extract_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œå¹¶æ·»åŠ æ–‡ä»¶åå‰ç¼€ä»¥åŒºåˆ†ä¸åŒæ–‡ä»¶çš„ç»“æœ
                        rel_path = os.path.relpath(file_path, extract_dir)
                        zip_path = os.path.join(base_name, rel_path)
                        logger.info(f"æ·»åŠ æ–‡ä»¶åˆ°åˆå¹¶ZIP: {zip_path}")
                        main_zip.write(file_path, zip_path)
        
        # æ€»ç»“å¤„ç†ç»“æœ
        progress(1.0, desc="ğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼")
        summary = {
            "status": "âœ… æˆåŠŸ" if fail_count == 0 else "âš ï¸ éƒ¨åˆ†æˆåŠŸ",
            "message": f"ğŸ‰ æ–‡ä»¶å¤„ç†å®Œæˆï¼æˆåŠŸ: {success_count}ï¼Œå¤±è´¥: {fail_count}",
            "æ€»æ–‡ä»¶æ•°": total_files,
            "æˆåŠŸæ•°": success_count,
            "å¤±è´¥æ•°": fail_count,
            "æ–‡ä»¶è¯¦æƒ…": all_results
        }
        logger.info(f"æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ: {summary}")
        return summary, main_output_path
    
    except Exception as e:
        logger.exception(f"æ‰¹é‡å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return {"error": f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}"}, None


def create_ui():
    """åˆ›å»ºç®€åŒ–ç‰ˆGradio UI"""
    with gr.Blocks(title="NC æµ‹è¯•ä¸­å¿ƒå†…éƒ¨PDF/HTMLè½¬æ¢å·¥å…·", css=CUSTOM_CSS) as demo:
        with gr.Column(elem_classes=["container"]):
            # æ ‡é¢˜å’Œè¯´æ˜
            with gr.Column(elem_classes=["header"]):
                gr.Markdown("# ğŸ“„ æµ‹è¯•ä¸­å¿ƒå†…éƒ¨PDF/HTMLè½¬æ¢å·¥å…·")
                gr.Markdown("åŸºäºGPDFè½¬æ¢ã€çŸ¥è¯†åº“ä¸Šä¼ ã€AIå¤§æ¨¡å‹æ¸…æ´—ç­‰åŠŸèƒ½ï¼Œæ”¯æŒæ‰¹é‡å¤„ç†ä¸Šä¼ PDFå’ŒHTMLæ–‡ä»¶ã€‚")

            # ä¸Šä¼ åŒºåŸŸ
            with gr.Column(elem_classes=["upload-section"]):
                gr.Markdown("## ğŸ“¤ ä¸Šä¼ PDF/HTMLæ–‡ä»¶")
                pdf_files = gr.File(label="é€‰æ‹©PDF/HTMLæ–‡ä»¶", file_types=[".pdf", ".html"], elem_id="pdf-upload", file_count="multiple")

                # æ·»åŠ è½¬æ¢é€‰é¡¹
                gr.Markdown("ğŸ”„ è½¬æ¢åå¤„ç†é€‰é¡¹")
                with gr.Row(elem_classes=["options-row"]):
                    upload_to_kb_flag = gr.Checkbox(label="ğŸ“š ä¸Šä¼ çŸ¥è¯†åº“", value=True)
                    kb_id_input = gr.Dropdown(
                        label="çŸ¥è¯†åº“IDï¼ˆTODO:è‡ªåŠ¨è·å–çŸ¥è¯†åº“åˆ—è¡¨ï¼Œæ˜¾ç¤ºæ ¼å¼ä¸ºï¼šçŸ¥è¯†åº“çš„åç§°ï¼‰",
                        choices=[DEFAULT_KB_ID],
                        value=DEFAULT_KB_ID
                    )
                with gr.Row(elem_classes=["options-row"]):
                    use_ai_flag = gr.Checkbox(label="ğŸ§  AIä¼˜åŒ–æ–‡æ¡£", value=True)
                    ai_model_input = gr.Dropdown(
                        label="AIæ¨¡å‹",
                        choices=[DEFAULT_AI_MODEL],
                        value=DEFAULT_AI_MODEL
                    )
                with gr.Row(elem_classes=["options-row"]):
                    max_chunk_size = gr.Slider(
                        label="æ–‡æœ¬å—æœ€å¤§å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰",
                        minimum=10000,
                        maximum=200000,
                        value=DEFAULT_MAX_CHUNK_SIZE,
                        step=10000,
                        info="å¤„ç†é•¿æ–‡æ¡£æ—¶çš„åˆ†å—å¤§å°ï¼Œè¿‡å¤§å¯èƒ½å¯¼è‡´AIå¤„ç†å¤±è´¥"
                    )

                upload_button = gr.Button("ğŸ“¤ ä¸Šä¼ å¹¶å¼€å§‹è½¬æ¢", variant="primary", size="lg")
                result_info = gr.JSON(label="è½¬æ¢ä¿¡æ¯", visible=False)

            # ä¸‹è½½åŒºåŸŸ
            with gr.Column(elem_classes=["download-section"]):
                gr.Markdown("## ğŸ“¥ ä¸‹è½½è½¬æ¢ç»“æœ")
                zip_output = gr.File(label="ZIPå‹ç¼©åŒ…")

            # é¡µè„š
            with gr.Column(elem_classes=["footer"]):
                gr.Markdown(
                    "Â© 2025 æµ‹è¯•ä¸­å¿ƒå†…éƒ¨PDF/HTMLè½¬æ¢å·¥å…· | åŸºäº[MinerU](https://github.com/opendatalab/MinerU)å¼€å‘ | ğŸ’¬ ä½¿ç”¨é—®é¢˜è”ç³»libiao1")

        # äº‹ä»¶å¤„ç†
        upload_button.click(
            fn=process_multiple_files,
            inputs=[pdf_files, upload_to_kb_flag, kb_id_input, use_ai_flag, ai_model_input, max_chunk_size],
            outputs=[result_info, zip_output],
            show_progress=True  # æ˜¾ç¤ºGradioå†…ç½®è¿›åº¦æ¡
        )

        # å½“ä¸Šä¼ çŸ¥è¯†åº“å¤é€‰æ¡†çŠ¶æ€å˜åŒ–æ—¶ï¼Œæ˜¾ç¤ºæˆ–éšè—çŸ¥è¯†åº“IDè¾“å…¥æ¡†
        upload_to_kb_flag.change(
            fn=show_kb_id_input,
            inputs=[upload_to_kb_flag],
            outputs=[kb_id_input]
        )

    return demo


if __name__ == "__main__":
    logger.info("=" * 50)
    logger.info("å¯åŠ¨PDFè½¬æ¢Webåº”ç”¨")
    logger.info("=" * 50)
    demo = create_ui()
    demo.queue()
    demo.launch(share=False, server_name='0.0.0.0')
